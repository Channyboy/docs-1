// Copyright (c) 2019, 2021 IBM Corporation and others.
// Licensed under Creative Commons Attribution-NoDerivatives
// 4.0 International (CC BY-ND 4.0)
//   https://creativecommons.org/licenses/by-nd/4.0/
//
// Contributors:
//     IBM Corporation
//
:page-description: The metrics contained in this reference list are all available for Open Liberty. Use metric data to effectively monitor the status of your microservice systems.
:seo-title: Metrics reference list - openliberty.io
:seo-description: The metrics contained in this reference list are all available for Open Liberty. Use metric data to effectively monitor the status of your microservice systems.
:page-layout: general-reference
:page-type: general
:base-metric-features: feature:mpMetrics-2.3[] or later
:vendor-metric-features: feature:mpMetrics-2.3[] or later
:grpc-client-metric-features: feature:grpcClient-1.0[] and feature:mpMetrics-2.3[] or later
:grpc-server-metric-features: feature:grpc-1.0[] and feature:mpMetrics-2.3[] or later
:ft-metric-features: feature:mpFaultTolerance-3.0[] and feature:mpMetrics-3.0[]
= Metrics reference list

The metrics reference list includes all the metrics that are available for Open Liberty.
Use metric data to effectively monitor the status of your microservice systems.

Metrics are emitted from a number of different places.
You can obtain them from applications, the Open Liberty runtime, and the Java virtual machine (JVM).
They can be gathered and stored in database tools, such as https://prometheus.io/[Prometheus], and displayed on dashboards, such as https://grafana.com/[Grafana].
For more information about building observability into your applications, see xref:microservice-observability-metrics.adoc[Microservice observability with metrics].

MicroProfile Metrics 2.3 explicitly enables the link:https://openliberty.io/docs/ref/feature/#monitor-1.0.html[Performance Monitoring feature].
If you use a version earlier than 2.3 of the MicroProfile Metrics feature, then you must also enable the Performance Monitoring feature.

In the table, the Prometheus metric names are listed after each metric.
The table also lists the metric types, metric units, and descriptions of all metrics that are available for Open Liberty.
Metric units are included along with both the metric names and Prometheus names as these units can differ because the Prometheus exporter scales metrics to a base unit.
For example, while the `ft.<name>.bulkhead.executionDuration` metric is recorded internally in nanoseconds, the Prometheus output is in seconds.
If no unit is listed next to the metric name, then no units are associated with that metric.
The last column of the table includes the feature or features that must be enabled to obtain that metric data.
{empty} +

.Metrics that are available for Open Liberty
[%header,cols="9,9,9,3,3"]
|===

|mpMetrics-3.x name
|mpMetrics-3.x Prometheus name(s)
|Type and description
|Feature(s) required
|Version introduced

|classloader.loadedClasses.count
|base_classloader_loadedClasses_count
|This metric is a gauge. The number of classes that are currently loaded in the JVM.
|{base-metric-features}
|

|classloader.loadedClasses.total
|base_classloader_loadedClasses_total
|This metric is a counter. The total number of classes that were loaded since the JVM started.
|{base-metric-features}
|

|classloader.unloadedClasses.total
|base_classloader_unloadedClasses_total
|This metric is a counter. The total number of classes that were unloaded since the JVM started.
|{base-metric-features}
|

|connectionpool.connectionHandles{datasource=<datasourceName>}
|vendor_connectionpool_connectionHandles{datasource=<dataSourceName>}
|This metric is a gauge. The number of connections that are in use. This number might include multiple connections that are shared from a single managed connection.
|{vendor-metric-features}
|

|connectionpool.create.total{datasource=<datasourceName>}
|vendor_connectionpool_create_total{datasource=<dataSourceName>}
|This metric is a counter. The total number of managed connections that were created since the pool creation.
|{vendor-metric-features}
|

|connectionpool.destroy.total{datasource=<datasourceName>}
|vendor_connectionpool_destroy_total{datasource=<dataSourceName>}
|This metric is a counter. The total number of managed connections that were destroyed since the pool creation.
|{vendor-metric-features}
|

|connectionpool.freeConnections{datasource=<datasourceName>}
|vendor_connectionpool_freeConnections{datasource=<dataSourceName>}
|This metric is a gauge. The number of managed connections in the free pool.
|{vendor-metric-features}
|

|connectionPool.inUseTime.total{datasource=<datasourceName>} / (milliseconds)
|vendor_connectionpool_inUseTime_total_seconds{datasource=<dataSourceName>} / (seconds)
|This metric is a gauge. The total time that all connections are in-use since the start of the server.
|{vendor-metric-features}
|

|connectionpool.managedConnections{datasource=<datasourceName>}
|vendor_connectionpool_managedConnections{datasource=<dataSourceName>}
|This metric is a gauge. The current sum of managed connections in the free, shared, and unshared pools.
|{vendor-metric-features}
|

|connectionpool.queuedRequests.total{datasource=<datasourceName>}
|vendor_connectionpool_queuedRequests_total{datasource=<dataSourceName>}
|This metric is a counter. The total number of connection requests that waited for a connection because of a full connection pool since the start of the server.
|{vendor-metric-features}
|

|connectionPool.usedConnections.total{datasource=<datasourceName>}
|vendor_connectionpool_usedConnections_total{datasource=<dataSourceName>}
|This metric is a counter. The total number of connection requests that waited because of a full connection pool or did not wait since the start of the server. Any connections that are currently in use are not included in this total.
|{vendor-metric-features}
|

|connectionpool.waitTime.total{datasource=<datasourceName>} / (milliseconds)
|vendor_connectionpool_waitTime_total_seconds{datasource=<dataSourceName>} / (seconds)
|This metric is a gauge. The total wait time on all connection requests since the start of the server.
|{vendor-metric-features}
|

|cpu.availableProcessors
|base_cpu_availableProcessors
|This metric is a gauge. The number of processors available to the JVM.
|{base-metric-features}
|

|cpu.processCpuLoad / (percent)
|base_cpu_processCpuLoad_percent / (percent)
|This metric is a gauge. The recent CPU usage for the JVM process.
|{base-metric-features}
|

|cpu.processCpuTime / (nanoseconds)
|base_cpu_processCpuTime_seconds / (seconds)
|This metric is a gauge. The CPU time for the JVM process.
|{base-metric-features}
|

|cpu.systemLoadAverage
|base_cpu_systemLoadAverage
|This metric is a gauge. The system load average for the last minute. If the system load average is not available, a negative value is displayed.
|{base-metric-features}
|

|
ft.bulkhead.calls.total{
    method="<name>",
    bulkheadResult=["accepted"\|"rejected"]
}
|base_ft_bulkhead_calls_total{
    method="<name>",
    bulkheadResult=["accepted"\|"rejected"]
}
|This metric is a counter. The number of times that the bulkhead logic was run. This is usually once per method call, but it might be zero if a circuit breaker prevented execution or more than once if the method call is retried. This metric is available when you use the `@Bulkhead` fault tolerance annotation.
|{ft-metric-features}
|

|ft.bulkhead.executionsRunning{method="<name>"}
|base_ft_bulkhead_executionsRunning{method="<name>"}
|This metric is a gauge. The number of currently running executions. This metric is available when you use the `@Bulkhead` fault tolerance annotation.
|{ft-metric-features}
|

|ft.bulkhead.executionsWaiting{method="<name>"}
|base_ft_bulkhead_executionsWaiting{method="<name>"}
|This metric is a gauge. The number of executions currently waiting in the queue. This metric is available when you use the `@Bulkhead` fault tolerance annotation and the `@Asynchronous` annotation.
|{ft-metric-features}
|

|ft.bulkhead.runningDuration{method="<name>"} / (nanoseconds)
|base_ft_bulkhead_runningDuration_min_seconds{method="<name>"}
base_ft_bulkhead_runningDuration_max_seconds{method="<name>"}
base_ft_bulkhead_runningDuration_mean_seconds{method="<name>"}
base_ft_bulkhead_runningDuration_stddev_seconds{method="<name>"}
base_ft_bulkhead_runningDuration_seconds_count{method="<name>"}
base_ft_bulkhead_runningDuration_seconds_sum{method="<name>"}
base_ft_bulkhead_runningDuration_seconds{
    method="<name>",
    quantile=["0.5"\|"0.75"\|"0.95"\|"0.98"\|"0.99"\|"0.999"]
} / seconds
|A histogram of the time that method executions spent running. This metric is available when you use the `@Bulkhead` fault tolerance annotation.
|{ft-metric-features}
|

|ft.bulkhead.waitingDuration{method="<name>"} / (nanoseconds)
|base_ft_bulkhead_waitingDuration_min_seconds{method="<name>"}
base_ft_bulkhead_waitingDuration_max_seconds{method="<name>"}
base_ft_bulkhead_waitingDuration_mean_seconds{method="<name>"}
base_ft_bulkhead_waitingDuration_stddev_seconds{method="<name>"}
base_ft_bulkhead_waitingDuration_seconds_count{method="<name>"}
base_ft_bulkhead_waitingDuration_seconds_sum{method="<name>"}
base_ft_bulkhead_waitingDuration_seconds{
    method="<name>",
    quantile=["0.5"\|"0.75"\|"0.95"\|"0.98"\|"0.99"\|"0.999"]
} / seconds
|A histogram of the time that method executions spent waiting in the queue. This metric is available when you use the `@Bulkhead` fault tolerance annotation and the `@Asynchronous` annotation.
|{ft-metric-features}
|

|ft.circuitbreaker.calls.total{
    method="<name>",
    circuitBreakerResult=["success"\|"failure"\|"circuitBreakerOpen"]
}
|base_ft_circuitbreaker_calls_total{
    method="<name>",
    circuitBreakerResult=["success"\|"failure"\|"circuitBreakerOpen"]
}
|This metric is a counter. The number of times that the circuit breaker logic was run. This will usually be once per method call, but may be more than once if the method call is retried. This metric is available when you use the `@CircuitBreaker` fault tolerance annotation.
|{ft-metric-features}
|

|ft.circuitbreaker.state.total{
    method="<name>",
    state=["open"\|"closed"\|"halfOpen"]
} / (nanoseconds)
|base_ft_circuitbreaker_state_total_seconds{
    method="<name>",
    state=["open"\|"closed"\|"halfOpen"]
} / (seconds)
|This metric is a gauge. The amount of time that the circuit breaker has spent in each state. These values increase monotonically. This metric is available when you use the `@CircuitBreaker` fault tolerance annotation.
|{ft-metric-features}
|

|ft.circuitbreaker.opened.total{method="<name>"}
|base_ft_circuitbreaker_opened_total{method="<name>"}
|This metric is a counter. The number of times that the circuit breaker has moved from close state to open state. This metric is available when you use the `@CircuitBreaker` fault tolerance annotation.
|{ft-metric-features}
|

|ft.invocations.total{
    method="<name>",
    result=["valueReturned"\|"exceptionThrown"],
    fallback=["applied"\|"notApplied"\|"notDefined"]
}
|base_ft_invocations_total{
    method="<name>",
    result=["valueReturned"\|"exceptionThrown"],
    fallback=["applied"\|"notApplied"\|"notDefined"]
}
|This metric is a counter. The number of times that the method was called.
|{ft-metric-features}
|

|ft.retry.calls.total{
    method="<name>",
    retried=["true"\|"false"],
    retryResult=["valueReturned"
                \|"exceptionNotRetryable"
                \|"maxRetriesReached"
                \|"maxDurationReached"]
}
|base_ft_retry_calls_total{
    method="<name>",
    retried=["true"\|"false"],
    retryResult=["valueReturned"
                \|"exceptionNotRetryable"
                \|"maxRetriesReached"
                \|"maxDurationReached"]
}
|This metric is a counter. The number of times that the retry logic was run. This will always be once per method call. This metric is available when you use the `@Retry` fault tolerance annotation.
|{ft-metric-features}
|

|ft.retry.retries.total{method="<name>"}
|base_ft_retry_retries_total{method="<name>"}
|This metric is a counter. The number of times that the method was retried. This metric is available when you use the `@Retry` fault tolerance annotation.
|{ft-metric-features}
|

|
ft.timeout.calls.total{
    method="<name>",
    timedOut=["true"\|"false"]
}
|base_ft_timeout_calls_total{
    method="<name>",
    timedOut=["true"\|"false"]
}
|This metric is a counter. The number of times that the timeout logic was run. This will usually be once per method call, but may be zero times if the circuit breaker prevents execution or more than once if the method is retried. This metric is available when you use the `@Timeout` fault tolerance annotation.
|{ft-metric-features}
|

|ft.timeout.executionDuration{method="<name>"} / (nanoseconds)
|base_ft_timeout_executionDuration_mean_seconds{method="<name>"}
base_ft_timeout_executionDuration_max_seconds{method="<name>"}
base_ft_timeout_executionDuration_min_seconds{method="<name>"}
base_ft_timeout_executionDuration_stddev_seconds{method="<name>"}
base_ft_timeout_executionDuration_seconds_count{method="<name>"}
base_ft_timeout_executionDuration_seconds{
    method="<name>",
    quantile=["0.5"\|"0.75"\|"0.95"\|"0.98"\|"0.99"\|"0.999"]
} / (seconds)
|A histogram of the execution time for the method. This metric is available when you use the `@Timeout` fault tolerance annotation.
|{ft-metric-features}
|

|gc.time{name=<gcName>} / (milliseconds)
|base_gc_time_seconds{name="<gcType>"} / (seconds)
|This metric is a gauge. The approximate accumulated garbage collection elapsed time. This metric displays `-1` if the garbage collection elapsed time is undefined for this collector.
|{base-metric-features}
|

|gc.total{name=<gcName>}
|base_gc_total{name="<gcType>"}
|This metric is a counter. The number of garbage collections that occurred. This metric displays `-1` if the garbage collection count is undefined for this collector.
|{base-metric-features}
|

|grpc.client.receivedMessages.total{grpc=<method_signature>}
|vendor_grpc_client_receivedMessages_total
|This metric is a counter. The number of stream messages received from the server.
|{grpc-client-metric-features}
|

|grpc.client.responseTime.total{grpc=<method_signature>} / (milliseconds)
|vendor_grpc_client_responseTime_total_seconds / (seconds)
|This metric is a gauge. The response time of completed RPCs.
|{grpc-client-metric-features}
|

|grpc.client.rpcCompleted.total{grpc=<method_signature>}
|vendor_grpc_client_rpcCompleted_total
|This metric is a counter. The number of RPCs completed on the client, regardless of success or failure.
|{grpc-client-metric-features}
|

|grpc.client.rpcStarted.total{grpc=<method_signature>}
|vendor_grpc_client_rpcStarted_total
|This metric is a counter. The number of RPCs started on the client.
|{grpc-client-metric-features}
|

|grpc.client.sentMessages.total{grpc=<method_signature>}
|vendor_grpc_client_sentMessages_total
|This metric is a counter. The number of stream messages sent by the client.
|{grpc-client-metric-features}
|

|grpc.server.receivedMessages.total{grpc=<service_name>}
|vendor_grpc_server_receivedMessages_total
|This metric is a counter. The number of stream messages received from the client.
|{grpc-server-metric-features}
|

|grpc.server.responseTime.total{grpc=<service_name>} / (milliseconds)
|vendor_grpc_server_responseTime_total_seconds / (seconds)
|This metric is a gauge. The response time of completed RPCs.
|{grpc-server-metric-features}
|

|grpc.server.rpcCompleted.total{grpc=<service_name>}
|vendor_grpc_server_rpcCompleted_total
|This metric is a counter. The number of RPCs completed on the server, regardless of success or failure.
|{grpc-server-metric-features}
|

|grpc.server.rpcStarted.total{grpc=<service_name>}
|vendor_grpc_client_rpcStarted_total
|This metric is a counter. The number of RPCs started on the server.
|{grpc-server-metric-features}
|

|grpc.server.sentMessages.total{grpc=<service_name>}
|vendor_grpc_server_sentMessages_total
|This metric is a counter. The number of stream messages sent by the server.
|{grpc-server-metric-features}
|

|jaxws.client.checkedApplicationFaults.total{endpoint=<endpointName>}
|vendor_jaxws_client_checkedApplicationFaults_total{endpoint=<endpointName>}
|This metric is a counter. The number of checked application faults.
|{vendor-metric-features}
|

|jaxws.client.invocations.total{endpoint=<endpointName>}
|vendor_jaxws_client_invocations_total{endpoint=<endpointName>}
|This metric is a counter. The number of invocations to this endpoint or operation.
|{vendor-metric-features}
|

|jaxws.client.logicalRuntimeFaults.total{endpoint=<endpointName>}
|vendor_jaxws_client_logicalRuntimeFaults_total{endpoint=<endpointName>}
|This metric is a counter. The number of logical runtime faults.
|{vendor-metric-features}
|

|jaxws.client.responseTime.total{endpoint=<endpointName>} / (milliseconds)
|vendor_jaxws_client_responseTime_total_seconds{endpoint=<endpointName>} / (seconds)
|This metric is a gauge. The total response handling time since the start of the server.
|{vendor-metric-features}
|

|jaxws.client.runtimeFaults.total{endpoint=<endpointName>}
|vendor_jaxws_client_runtimeFaults_total{endpoint=<endpointName>}
|This metric is a counter. The number of runtime faults.
|{vendor-metric-features}
|

|jaxws.client.uncheckedApplicationFaults.total{endpoint=<endpointName>}
|vendor_jaxws_client_uncheckedApplicationFaults_total{endpoint=<endpointName>}
|This metric is a counter. The number of unchecked application faults.
|{vendor-metric-features}
|

|jaxws.server.checkedApplicationFaults.total{endpoint=<endpointName>}
|vendor_jaxws_server_checkedApplicationFaults_total{endpoint=<endpointName>}
|This metric is a counter. The number of checked application faults.
|{vendor-metric-features}
|

|jaxws.server.invocations.total{endpoint=<endpointName>}
|vendor_jaxws_server_invocations_total{endpoint=<endpointName>}
|This metric is a counter. The number of invocations to this endpoint or operation.
|{vendor-metric-features}
|

|jaxws.server.logicalRuntimeFaults.total{endpoint=<endpointName>}
|vendor_jaxws_server_logicalRuntimeFaults_total{endpoint=<endpointName>}
|This metric is a counter. The number of logical runtime faults.
|{vendor-metric-features}
|

|jaxws.server.responseTime.total{endpoint=<endpointName>} / (milliseconds)
|vendor_jaxws_server_responseTime_total_seconds{endpoint=<endpointName>} / (seconds)
|This metric is a gauge. The total response handling time since the start of the server.
|{vendor-metric-features}
|

|jaxws.server.runtimeFaults.total{endpoint=<endpointName>}
|vendor_jaxws_server_runtimeFaults_total{endpoint=<endpointName>}
|This metric is a counter. The number of runtime faults.
|{vendor-metric-features}
|

|jaxws.server.uncheckedApplicationFaults.total{endpoint=<endpointName>}
|vendor_jaxws_server_uncheckedApplicationFaults_total{endpoint=<endpointName>}
|This metric is a counter. The number of unchecked application faults.
|{vendor-metric-features}
|

|jvm.uptime / (milliseconds)
|base_jvm_uptime_seconds / (seconds)
|This metric is a gauge. The time elapsed since the start of the JVM.
|{base-metric-features}
|

|memory.committedHeap / (bytes)
|base_memory_committedHeap_bytes / (bytes)
|This metric is a gauge. The amount of memory that is committed for the JVM to use.
|{base-metric-features}
|

|memory.maxHeap / (bytes)
|base_memory_maxHeap_bytes / (bytes)
|This metric is a gauge. The maximum amount of heap memory that can be used for memory management. This metric displays `-1` if the maximum heap memory size is undefined. This amount of memory is not guaranteed to be available for memory management if it is greater than the amount of committed memory.
|{base-metric-features}
|

|memory.usedHeap / (bytes)
|base_memory_usedHeap_bytes / (bytes)
|This metric is a gauge. The amount of used heap memory.
|{base-metric-features}
|

|REST.request
|base_REST_request_total{class="<fully_qualified_class_name>",method="<method_signature>"} {empty}+
 {empty}+
 base_REST_request_elapsedTime_seconds{class="<fully_qualified_class_name>",method="<method_signature>"} / (seconds)
|This metric is a simple timer. The number of invocations and total response time of this RESTful resource method since the server started. The metric doesn't record the count of invocations nor the elapsed time if an unmapped exception occurs. This metric also tracks the highest recorded time duration within the previous completed full minute and lowest recorded time duration within the previous completed full minute.
|{base-metric-features}
|

|REST.request.unmappedException.total
|base_REST_request_unmappedException_total{class="<fully_qualified_class_name>",method="<method_signature>"}
|This metric is a counter. The total number of unmapped exceptions that occur from this RESTful resource method since the server started.
|{base-metric-features}
|

|servlet.request.total{servlet=<servletName>}
|vendor_servlet_request_total{servlet=<servletname>}
|This metric is a counter. The total number of visits to this servlet since the start of the server.
|{vendor-metric-features}
|

|servlet.responseTime.total{servlet=<servletName>} / (nanoseconds)
|vendor_servlet_responseTime_total_seconds / (seconds)
|This metric is a gauge. The total of the servlet response time since the start of the server.
|{vendor-metric-features}
|

|session.activeSessions{appname=<appName>}
|vendor_session_activeSessions{appname=<appName>}
|This metric is a gauge. The number of concurrently active sessions. A session is considered active if the application server is processing a request that uses that user session.
|{vendor-metric-features}
|

|session.create.total{appname=<appName>}
|vendor_session_create_total{appname=<appName>}
|This metric is a gauge. The number of sessions that logged in since this metric was enabled.
|{vendor-metric-features}
|

|session.invalidated.total{appname=<appName>}
|vendor_session_invalidated_total{appname=<appName>}
|This metric is a counter. The number of sessions that logged out since this metric was enabled.
|{vendor-metric-features}
|

|session.invalidatedbyTimeout.total{appname=<appName>}
|vendor_session_invalidatedbyTimeout_total{appname=<appName>}
|This metric is a counter. The number of sessions that logged out because of a timeout since this metric was enabled.
|{vendor-metric-features}
|

|session.liveSessions{appname=<appName>}
|vendor_session_liveSessions{appname=<appName>}
|This metric is a gauge. The number of users that are currently logged in since this metric was enabled.
|{vendor-metric-features}
|

|thread.count
|base_thread_count
|This metric is a gauge. The current number of live threads, including both daemon and non-daemon threads.
|{base-metric-features}
|

|thread.daemon.count
|base_thread_daemon_count
|This metric is a gauge. The current number of live daemon threads.
|{base-metric-features}
|

|thread.max.count
|base_thread_max_count
|This metric is a gauge. The peak live thread count since the JVM started or the peak was reset. This thread count includes both daemon and non-daemon threads.
|{base-metric-features}
|

|threadpool.activeThreads{pool=<poolName>}
|vendor_threadpool_activeThreads{pool="<poolName>"}
|This metric is a gauge. The number of threads that are actively running tasks.
|{vendor-metric-features}
|

|threadpool.size{pool=<poolName>}
|vendor_threadpool_size{pool="<poolName>"}
|This metric is a gauge. The size of the thread pool.
|{vendor-metric-features}
|

|===

== See also

* Guide: link:/guides/microprofile-metrics.html[Providing metrics from a microservice]
* xref:reference:metrics-1-dif.adoc[Differences between MicroProfile Metrics versions]
* xref:microservice-observability-metrics.adoc[Microservice observability with metrics]
